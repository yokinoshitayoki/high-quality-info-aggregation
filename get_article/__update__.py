import os
import sys
import json
import time
import sqlite3
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ get_articleç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'get_article'))

def load_title_link_data():
    """åŠ è½½æ›´æ–°åçš„title_link_upd.jsonæ–‡ä»¶"""
    try:
        # è¯»å–bind/upd_bind/title_link_upd.jsonæ–‡ä»¶
        json_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 
                                'bind', 'upd_bind', 'title_link_upd.json')
        
        if not os.path.exists(json_path):
            print(f"æœªæ‰¾åˆ°æ›´æ–°æ–‡ä»¶: {json_path}")
            return None
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        with open(json_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if not content:
                print("æ›´æ–°æ–‡ä»¶ä¸ºç©ºï¼Œæ²¡æœ‰æ•°æ®å¯å¤„ç†")
                return None
            data = json.loads(content)
        
        print(f"æˆåŠŸåŠ è½½ {len(data)} æ¡æ›´æ–°æ•°æ®")
        return data
    
    except Exception as e:
        print(f"åŠ è½½æ›´æ–°æ•°æ®å¤±è´¥: {e}")
        return None

def get_article_content(title, link_info):
    """æ ¹æ®ç½‘ç«™ç±»å‹è°ƒç”¨ç›¸åº”çš„çˆ¬è™«è·å–æ–‡ç« å†…å®¹"""
    try:
        link, date, source = link_info
        
        if source == 'è™å—…ç½‘':
            from huxiu_crawler_artcle import get_article_content as huxiu_crawler
            result = huxiu_crawler(link)
        elif source == 'æœç‹ç½‘':
            from sohu_crawler_artcle import get_article_content as sohu_crawler
            result = sohu_crawler(link)
        elif source == 'è…¾è®¯ç½‘':
            from tencent_crawler_artcle import get_article_content as tencent_crawler
            result = tencent_crawler(link)
        else:
            print(f"æœªçŸ¥çš„ç½‘ç«™æ¥æº: {source}")
            return None
        
        if result['success']:
            print(f"æˆåŠŸè·å–æ–‡ç« : {title}")
            return result['content']
        else:
            print(f"è·å–æ–‡ç« å¤±è´¥: {title} - {result['error']}")
            return None
            
    except Exception as e:
        print(f"å¤„ç†æ–‡ç« æ—¶å‡ºé”™: {title} - {e}")
        return None

def process_single_article(title, link_info):
    """å¤„ç†å•ç¯‡æ–‡ç« """
    content = get_article_content(title, link_info)
    if content:
        # å°†æ–‡ç« å†…å®¹æ·»åŠ åˆ°åŸå§‹æ•°æ®ä¸­
        return title, list(link_info) + [content]
    else:
        # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›Noneè¡¨ç¤ºåˆ é™¤è¯¥æ•°æ®
        return None

def process_article_batch(articles_batch):
    """å¤„ç†ä¸€æ‰¹æ–‡ç«  - å¹¶è¡Œå¤„ç†"""
    results = {}
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ–‡ç« 
    with ThreadPoolExecutor(max_workers=5) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_title = {
            executor.submit(process_single_article, title, link_info): title
            for title, link_info in articles_batch.items()
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_title):
            title = future_to_title[future]
            try:
                result = future.result()
                if result is not None:
                    title, article_data = result
                    results[title] = article_data
                    print(f"âœ… æˆåŠŸè·å–: {title}")
                else:
                    print(f"âŒ åˆ é™¤å¤±è´¥æ•°æ®: {title}")
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {title} - {e}")
    
    return results

def save_to_database(all_results):
    """å°†æ–‡ç« å†…å®¹ä¿å­˜åˆ°æ•°æ®åº“ï¼Œåªæ›´æ–°æˆåŠŸçˆ¬å–çš„æ–‡ç« å†…å®¹"""
    try:
        # è¿æ¥æ•°æ®åº“
        db_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'database', 'title_link.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æ ‡é¢˜
        cursor.execute('SELECT title FROM title_link')
        db_titles = {row[0] for row in cursor.fetchall()}
        
        # è·å–æˆåŠŸçˆ¬å–çš„æ–‡ç« æ ‡é¢˜
        success_titles = set(all_results.keys())
        
        # åªæ›´æ–°æˆåŠŸçˆ¬å–çš„æ–‡ç« å†…å®¹ï¼Œä¸åˆ é™¤ä»»ä½•ç°æœ‰æ•°æ®
        updated_count = 0
        skipped_count = 0
        
        for title, article_data in all_results.items():
            if len(article_data) > 3:  # ç¡®ä¿æœ‰å†…å®¹å­—æ®µ
                content = article_data[3]
                try:
                    # æ£€æŸ¥æ–‡ç« æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
                    if title in db_titles:
                        cursor.execute('UPDATE title_link SET content = ? WHERE title = ?', (content, title))
                        if cursor.rowcount > 0:
                            updated_count += 1
                            print(f"âœ… æ›´æ–°æ–‡ç« å†…å®¹: {title}")
                        else:
                            skipped_count += 1
                            print(f"âš ï¸ æ–‡ç« ä¸å­˜åœ¨äºæ•°æ®åº“: {title}")
                    else:
                        skipped_count += 1
                        print(f"âš ï¸ æ–‡ç« ä¸å­˜åœ¨äºæ•°æ®åº“: {title}")
                except Exception as e:
                    print(f"âŒ æ›´æ–°æ•°æ®åº“å¤±è´¥ {title}: {e}")
        
        # æäº¤æ›´æ”¹
        conn.commit()
        conn.close()
        
        print(f"ğŸ“Š æ•°æ®åº“æ“ä½œå®Œæˆ:")
        print(f"   âœ… æˆåŠŸæ›´æ–°: {updated_count} ç¯‡æ–‡ç« å†…å®¹")
        print(f"   âš ï¸ è·³è¿‡å¤„ç†: {skipped_count} ç¯‡æ–‡ç« ï¼ˆä¸åœ¨æ•°æ®åº“ä¸­ï¼‰")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼šä»æ›´æ–°æ•°æ®è·å–æ–‡ç« å†…å®¹"""
    print("å¼€å§‹å¤„ç†æ›´æ–°æ•°æ®æ–‡ç« å†…å®¹çˆ¬å–ä»»åŠ¡...")
    
    # åŠ è½½æ›´æ–°æ•°æ®
    title_link_data = load_title_link_data()
    if not title_link_data:
        print("æ— æ³•åŠ è½½æ›´æ–°æ•°æ®ï¼Œç¨‹åºé€€å‡º")
        return
    
    # æŒ‰ç½‘ç«™åˆ†ç»„æ•°æ®
    huxiu_articles = {}
    sohu_articles = {}
    tencent_articles = {}
    
    for title, link_info in title_link_data.items():
        source = link_info[2]  # ç¬¬ä¸‰ä¸ªå…ƒç´ æ˜¯ç½‘ç«™æ¥æº
        if source == 'è™å—…ç½‘':
            huxiu_articles[title] = link_info
        elif source == 'æœç‹ç½‘':
            sohu_articles[title] = link_info
        elif source == 'è…¾è®¯ç½‘':
            tencent_articles[title] = link_info
    
    print(f"æ›´æ–°æ•°æ®åˆ†ç»„å®Œæˆ:")
    print(f"è™å—…ç½‘: {len(huxiu_articles)} ç¯‡")
    print(f"æœç‹ç½‘: {len(sohu_articles)} ç¯‡")
    print(f"è…¾è®¯ç½‘: {len(tencent_articles)} ç¯‡")
    
    # åˆå¹¶æ‰€æœ‰æ–‡ç« åˆ°ä¸€ä¸ªå­—å…¸ä¸­
    all_articles = {}
    all_articles.update(huxiu_articles)
    all_articles.update(sohu_articles)
    all_articles.update(tencent_articles)
    
    print(f"å¼€å§‹å¹¶è¡Œå¤„ç† {len(all_articles)} ç¯‡æ›´æ–°æ–‡ç« ...")
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡ç« 
    all_results = process_article_batch(all_articles)
    
    # ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
    print(f"æ€»å…±å¤„ç†äº† {len(all_results)} ç¯‡æ›´æ–°æ–‡ç« ")
    
    # ç»Ÿè®¡æˆåŠŸè·å–å†…å®¹çš„æ–‡ç« æ•°é‡
    success_count = sum(1 for article_data in all_results.values() 
                      if len(article_data) > 3 and article_data[3])
    
    print(f"æˆåŠŸè·å–å†…å®¹çš„æ–‡ç« : {success_count}/{len(all_results)}")
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    if save_to_database(all_results):
        print("âœ… æ‰€æœ‰æ›´æ–°æ–‡ç« å†…å®¹å·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
    else:
        print("âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
    
    # åŒæ—¶ä¿å­˜ä¸€ä»½JSONå¤‡ä»½
    output_dir = os.path.dirname(__file__)  # ç›´æ¥ä½¿ç”¨å½“å‰ç›®å½•
    output_file = os.path.join(output_dir, 'updated_articles_with_content.json')
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ æ›´æ–°æ–‡ç« JSONå¤‡ä»½å·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ›´æ–°æ–‡ç« JSONå¤‡ä»½å¤±è´¥: {e}")

if __name__ == "__main__":
    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œ
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs('../huxiu_data', exist_ok=True)
    os.makedirs('../sohu_data', exist_ok=True)
    os.makedirs('../qq_data', exist_ok=True)
    os.makedirs('../all_data', exist_ok=True)
    
    main() 